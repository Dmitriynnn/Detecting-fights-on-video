{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8XkwwCf6kAz"
      },
      "source": [
        "В этой части обученная нейросеть проверяется на видеозаписях, которые она не \"видела\". В основе распознавания видеозаписи лежит лежит модернизированная функция из первой части. Кадр распознается и нормированные данные ключевых точек собираются в словарь для каждого человека, и далее рассчитываются косинус и синус углов относительно вертикали для положения ярук и ног. При накоплении данных за продолжитльность кадров, равной той, на которой обучалась нейросеть, эти данные подаются на вход обученной нейросети. Если нейросеть выдает результат, что id является участником драки, то он обводится красным Bounding boxe и свреху появляяяется янадпись \"Fight\". На выходе раздела \"Запуск функции распознавания в папке\" получаем распознанное видео, на котором учатсиники драк обведены карсными рамками."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KX70EtXQ_LwD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-20 07:57:05.651573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-20 07:57:05.666255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-20 07:57:05.670756: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-20 07:57:05.682014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-20 07:57:06.253400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Установка OpenCV\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Установка NumPy\n",
        "!pip install numpy\n",
        "\n",
        "# Установка Pandas\n",
        "!pip install pandas\n",
        "\n",
        "# Установка TensorFlow\n",
        "!pip install tensorflow\n",
        "\n",
        "# Установка Ultralytics для YOLO\n",
        "!pip install ultralytics\n",
        "\n",
        "# Установка tqdm для отображения прогресса\n",
        "!pip install tqdm\n",
        "\n",
        "# Проверка успешной установки\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Все зависимости успешно установлены и импортированы!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/YX5ATloUrWM\n",
            "[youtube] YX5ATloUrWM: Downloading webpage\n",
            "[youtube] YX5ATloUrWM: Downloading ios player API JSON\n",
            "[youtube] YX5ATloUrWM: Downloading web creator player API JSON\n",
            "[youtube] YX5ATloUrWM: Downloading m3u8 information\n",
            "[info] YX5ATloUrWM: Downloading 1 format(s): 244+251\n",
            "[download] Destination: test/lecture_1.f244.webm\n",
            "[download] 100% of    6.99MiB in 00:00:02 at 3.04MiB/s     \n",
            "[download] Destination: test/lecture_1.f251.webm\n",
            "[download] 100% of  943.70KiB in 00:00:00 at 2.41MiB/s   \n",
            "[Merger] Merging formats into \"test/lecture_1.mp4\"\n",
            "Deleting original file test/lecture_1.f244.webm (pass -k to keep)\n",
            "Deleting original file test/lecture_1.f251.webm (pass -k to keep)\n",
            "Downloaded lecture_1 as test/lecture_1.mp4\n"
          ]
        }
      ],
      "source": [
        "import yt_dlp\n",
        "\n",
        "# Создаем папку 'test', если она не существует\n",
        "os.makedirs('test', exist_ok=True)\n",
        "\n",
        "# Список URL-адресов видео\n",
        "lectures = [\n",
        "    \"https://youtu.be/YX5ATloUrWM\"\n",
        "]\n",
        "\n",
        "def download_video(url, index):\n",
        "    try:\n",
        "        # Автоматически генерируем имя файла на основе индекса\n",
        "        title = f'lecture_{index + 1}'\n",
        "        \n",
        "        ydl_opts = {\n",
        "            'format': 'bestvideo+bestaudio/best',  # Загружаем лучшее видео и лучшее аудио и объединяем\n",
        "            'outtmpl': os.path.join('test', f'{title}.mp4'),  # Сохраняем в папке 'test'\n",
        "            'merge_output_format': 'mp4',  # Объединяем видео и аудио в формате mp4\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "            print(f\"Downloaded {title} as {os.path.join('test', f'{title}.mp4')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download video at {url}. Error: {e}\")\n",
        "\n",
        "# Скачивание всех лекций\n",
        "for index, url in enumerate(lectures):\n",
        "    download_video(url, index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFCkdkUb8LfC",
        "outputId": "2ce18e3c-e350-42db-9cf9-d10b017fce41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1724140639.673379  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.677462  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.680272  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.684139  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.686882  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.689540  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.807074  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.808520  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1724140639.809883  104006 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-08-20 07:57:19.811174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22355 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# Загрузка обученной модели для распознавания\n",
        "\n",
        "model_path = f'models/best_model_86_3_good.keras'\n",
        "\n",
        "model = tf.keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Функция возвращает синус и косинус угла, между линией, образованной координами двух точек, и вертикалью\n",
        "import math\n",
        "\n",
        "def calculate_angle(point1, point2):\n",
        "    # Проверяем, равна ли любая из координат точек нулю\n",
        "    if 0 in point1 or 0 in point2:\n",
        "        return 0, 0\n",
        "\n",
        "    # Вычисляем вектор AB\n",
        "    vector_AB = (point2[0] - point1[0], point2[1] - point1[1])\n",
        "\n",
        "    # Вычисляем скалярное произведение векторов AB и (0, -1)\n",
        "    dot_product = vector_AB[0] * 0 + vector_AB[1] * -1\n",
        "\n",
        "    # Вычисляем длину вектора AB\n",
        "    length_AB = math.sqrt(vector_AB[0]**2 + vector_AB[1]**2)\n",
        "\n",
        "    # Проверяем, не является ли длина вектора нулем (чтобы избежать деления на ноль)\n",
        "    if length_AB == 0:\n",
        "        return 0, 0\n",
        "\n",
        "    # Вычисляем косинус угла между векторами AB и (0, -1)\n",
        "    cos_angle = dot_product / length_AB\n",
        "\n",
        "    # Вычисляем синус угла между векторами AB и CD\n",
        "    if cos_angle < -1:\n",
        "      cos_angle = -1\n",
        "    elif cos_angle > 1:\n",
        "      cos_angle = 1\n",
        "\n",
        "    sin_angle = math.sqrt(1 - cos_angle**2)\n",
        "\n",
        "    # Возвращаем косинус и синус угла\n",
        "    return cos_angle, sin_angle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aZlGyZ3zFzvw"
      },
      "outputs": [],
      "source": [
        "# @title Функция распознает драку на видео и помещает дерущегося человека в красную рамку.\n",
        "def extract_predictions_angles(Path, model_fights, count_frame, Out_path = None, model_name = 'yolov8x-pose.pt'):\n",
        "\n",
        "  _, FileName = os.path.split(Path)\n",
        "  _, Ext = os.path.splitext(FileName)\n",
        "\n",
        "  # Создаем путь для сохранения файлов\n",
        "  if not Out_path:\n",
        "    Out_path = Path[:-len(Ext)]\n",
        "  else:\n",
        "    Out_path = os.path.join(Out_path, FileName[:-len(Ext)])\n",
        "\n",
        "  # Инициализация модели\n",
        "  model = YOLO(model_name)\n",
        "\n",
        "  # Переменные для шрифта номера кадра\n",
        "  font = cv2.FONT_HERSHEY_COMPLEX\n",
        "\n",
        "  # Создать объект захвата видео\n",
        "  video_in = cv2.VideoCapture(Path)\n",
        "\n",
        "  # Если видео не удалось открыть\n",
        "  if (video_in.isOpened() == False):\n",
        "    # Сообщение об ошибке\n",
        "    print('Не удалось считать кадр из видео!')\n",
        "    # Освобождаем объект захвата видео\n",
        "    video_in.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "  else:\n",
        "    # Количество кадров в секунду (примерная оценка)\n",
        "    fps = int(video_in.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Всего кадров (примерная оценка)\n",
        "    frames = int(video_in.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Разрешение видео\n",
        "    width = int(video_in.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video_in.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Вывод информации о файле\n",
        "    print('В видеофайле c частотой кадров: '+str(fps)+' кадр(а,ов)/сек\\nразрешением: '+ str(width)+'x'+str(height)+'\\nсодержится (но это не точно): '+ str(frames)+' кадр(а,ов).')\n",
        "\n",
        "    # Создаем объект записи видео для вывода результатов\n",
        "    video_out = cv2.VideoWriter(Out_path+'_out.avi',cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
        "\n",
        "    # Создаем датафрейм pandas для сохранения данных\n",
        "    Data_df = pd.DataFrame(columns=['Frame', 'Id', 'Coords', 'Keypoints', 'Normalized_KP', 'Conf','KP_Conf'])\n",
        "\n",
        "    # Создаем словарь для хранения треков\n",
        "    track_history = defaultdict(lambda: [])\n",
        "\n",
        "    # Создаем словарь для хранения нормализованных координат человека\n",
        "    normalized_KP_predict = defaultdict(lambda: [])\n",
        "\n",
        "    KP_predict = defaultdict(lambda: [])\n",
        "\n",
        "    # Инициализируем счетчик кадров\n",
        "    frame_num = 0\n",
        "\n",
        "    # Прыгаем к нужному кадру\n",
        "    if not frame_num == 0:\n",
        "      if 0 < frame_num < frames:\n",
        "        video_in.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
        "      else:\n",
        "        print('Стартовый кадр задан не корректно и будет сброшен на 0!')\n",
        "        frame_num = 0\n",
        "\n",
        "    # Считываем кадр\n",
        "    is_read, frame = video_in.read()\n",
        "    with tqdm(total=frames) as pbar:\n",
        "      while is_read:\n",
        "        # Обрабатываем кадр\n",
        "        results = model.track(frame, persist=True, verbose=False)\n",
        "        try:\n",
        "          # Извлекаем BBoxы и ID треков\n",
        "          boxes_xywh = results[0].boxes.xywh.cpu().tolist()\n",
        "          boxes_xyxy = results[0].boxes.xyxy.cpu().tolist()\n",
        "          track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "          confs = results[0].boxes.conf.cpu().tolist()\n",
        "\n",
        "          # Извлекаем относительные положени ключевых точек и уверенность сети в их определении\n",
        "          all_keypoints = results[0].keypoints.xy.cpu().tolist()\n",
        "          all_kp_confs = results[0].keypoints.conf.cpu().tolist()\n",
        "\n",
        "          for box_xywh, box_xyxy, track_id, conf, keypoints, kp_confs in zip(boxes_xywh, boxes_xyxy, track_ids, confs, all_keypoints, all_kp_confs):\n",
        "\n",
        "              # Определяем координаты рамки\n",
        "              x, y, w, h = box_xywh\n",
        "              x_min, y_min, x_max, y_max = box_xyxy\n",
        "\n",
        "              # Вычисляем нормированные значения keypoints\n",
        "              delta = [x_min, y_min]\n",
        "              scaler = [x_max - x_min, y_max - y_min]\n",
        "\n",
        "              normalized_KP = []\n",
        "              # Вариант сохранения нулевых normalized_KP для нулевых значений keypoints\n",
        "              for coord in keypoints:\n",
        "                  if coord == [0.0, 0.0]:\n",
        "                      normalized_KP.append([-1.0, -1.0])\n",
        "                  else:\n",
        "                      normalized_coord = ((np.asarray(coord) - np.asarray(delta)) / np.asarray(scaler)).tolist()\n",
        "                      normalized_KP.append(normalized_coord)\n",
        "\n",
        "              # Добавляем данные в датафрейм\n",
        "              Data_df.loc[len(Data_df.index)] = [frame_num, track_id, box_xyxy, keypoints, normalized_KP, conf, kp_confs]\n",
        "\n",
        "              # Добавление normalized_KP в словарь\n",
        "              KP_predict = normalized_KP_predict[track_id]\n",
        "              KP_predict.append(keypoints)\n",
        "              if len(KP_predict) == count_frame:\n",
        "                angles_summ = []\n",
        "                for item in KP_predict:\n",
        "\n",
        "                  angles = []\n",
        "                  # плечо\n",
        "                  angles += [calculate_angle(item[5], item[7])]\n",
        "                  angles += [calculate_angle(item[6], item[8])]\n",
        "                  # предплечье\n",
        "                  angles += [calculate_angle(item[7], item[9])]\n",
        "                  angles += [calculate_angle(item[8], item[10])]\n",
        "                  # бедро\n",
        "                  angles += [calculate_angle(item[11], item[13])]\n",
        "                  angles += [calculate_angle(item[12], item[14])]\n",
        "                  # гоень\n",
        "                  angles += [calculate_angle(item[13], item[15])]\n",
        "                  angles += [calculate_angle(item[14], item[16])]\n",
        "                  angles_summ.append(angles)\n",
        "\n",
        "                KP_predict = np.array(angles_summ)\n",
        "                KP_predict = np.array(KP_predict).reshape(1, count_frame, 8, 2)\n",
        "                prediction = model_fights.predict(KP_predict, verbose=0)\n",
        "                normalized_KP_predict[track_id].pop(0)\n",
        "\n",
        "                if prediction[0][0] > 0.90:\n",
        "                      # Преобразуем координаты в целые числа\n",
        "                  x, y, w, h = int(x), int(y), int(w), int(h)\n",
        "                  x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
        "\n",
        "                  # Наносим рамку на кадр\n",
        "                  cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 0, 255), 3)  # Цвет рамки: красный, толщина: 3 пикселя\n",
        "\n",
        "                  # Добавляем надпись на кадр над рамкой\n",
        "                  text = \"fight\"  # Ваш текст\n",
        "                  org = (x_min, y_min - 10)  # Координаты начала текста (над рамкой)\n",
        "                  font = cv2.FONT_HERSHEY_SIMPLEX  # Шрифт\n",
        "                  font_scale = 1  # Масштаб шрифта\n",
        "                  font_color = (0, 0, 255)  # Цвет текста: красный\n",
        "                  thickness = 3  # Толщина линии\n",
        "                  cv2.putText(frame, text, org, font, font_scale, font_color, thickness)\n",
        "\n",
        "          # Сохраняем обработанный кадр в видео\n",
        "          video_out.write(frame)\n",
        "          # Обновление прогресс-бара\n",
        "\n",
        "        except:\n",
        "          # Сохраняем обработанный кадр в видео\n",
        "          video_out.write(frame)\n",
        "        # Убеждаемся, что прогресс-бар достиг 100%\n",
        "\n",
        "        # Считываем следующий кадр\n",
        "        is_read, frame = video_in.read()\n",
        "        pbar.update(1)\n",
        "        # Увеличиваем счетчик кадров\n",
        "        frame_num += 1\n",
        "\n",
        "    pbar.close()\n",
        "    # Освобождаем объекты видео\n",
        "    video_in.release()\n",
        "    video_out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "    return [FileName, Out_path+'_out.avi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "61SpFY0o_6WS"
      },
      "outputs": [],
      "source": [
        "# @title Вспомогательные функции\n",
        "\n",
        "# Контекстный менеджер для измерения времени операций\n",
        "class timex:\n",
        "    def __enter__(self):\n",
        "        # Фиксация времени старта процесса\n",
        "        self.t = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        # Вывод времени работы\n",
        "        # Расчет времени выполнения\n",
        "        result_time = time.time()-self.t\n",
        "        hour = int(result_time//3600)\n",
        "        min = int(result_time//60)-hour*60\n",
        "        sec = int(round(result_time%60))\n",
        "        msec = round(1000*result_time%60)\n",
        "\n",
        "        if hour > 0:\n",
        "          print('Время обработки: ' + str(hour)+' час. ' + str(min)+' мин.')\n",
        "        elif min > 0:\n",
        "          print('Время обработки: ' + str(min)+' мин. ' + str(sec)+' сек.')\n",
        "        elif sec > 0:\n",
        "          print('Время обработки: ' + str(sec)+' сек.')\n",
        "        else:\n",
        "          print('Время обработки: ' + str(msec)+' мс.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqNsUWkM7Xq0",
        "outputId": "90863104-65bc-4fad-e70d-c21e7b32a758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Начало обработки файла lecture_1.mp4.\n",
            "В видеофайле c частотой кадров: 29 кадр(а,ов)/сек\n",
            "разрешением: 480x848\n",
            "содержится (но это не точно): 2072 кадр(а,ов).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2072 [00:00<34:27,  1.00it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1724140650.946081  104111 service.cc:146] XLA service 0x7fe228004100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1724140650.946109  104111 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
            "2024-08-20 07:57:30.953632: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-08-20 07:57:30.976246: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
            "I0000 00:00:1724140651.111128  104111 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            " 13%|█▎        | 271/2072 [00:19<02:54, 10.31it/s]"
          ]
        }
      ],
      "source": [
        "# @title Запуск функции распознавания в папке\n",
        "with timex():\n",
        "  # Путь к каталогу с видео для обработки\n",
        "  source = 'test/'\n",
        "\n",
        "  # Путь для сохранения результатов обработки\n",
        "  destination = 'result/'\n",
        "\n",
        "  # Список расширений файлов (на случай если в папке еще что-то есть)\n",
        "  ext_list = ['.mp4','.avi','.mov']\n",
        "\n",
        "  # Список для хранения имен файлов\n",
        "  Files_List = []\n",
        "\n",
        "  # Список для хранения имен файлов\n",
        "  Out_Video_List = []\n",
        "\n",
        "  # Список для хранения имен файлов\n",
        "  Out_Pandas_List = []\n",
        "\n",
        "  # кол-во кадров идущих подряд, используемых при обучении\n",
        "  count_frame = model.input_shape[1]\n",
        "\n",
        "  # Создание каталога для сохранения при его отсутствии\n",
        "  if not os.path.exists(destination):\n",
        "    os.mkdir(destination)\n",
        "\n",
        "  if os.path.isfile(destination):\n",
        "    print('Существует файл идентичный имени каталога!\\nУдалите/переименуйте файл или измените путь для сохранения.')\n",
        "  else:\n",
        "    # Запуск обработки\n",
        "    for file_name in os.listdir(source):\n",
        "      _, ext = os.path.splitext(file_name)\n",
        "      if ext in ext_list:\n",
        "        with timex():\n",
        "          print(f'\\nНачало обработки файла {file_name}.')\n",
        "          FileName, Out_Video = extract_predictions_angles(os.path.join(source,file_name), model, count_frame, destination, 'yolov8x-pose.pt')\n",
        "          Files_List.append(FileName)\n",
        "          Out_Video_List.append(Out_Video)\n",
        "          print(f'\\nФайл обработан.\\nВидео сохранено в: {Out_Video}')\n",
        "\n",
        "    print(f'\\nОбработка закончена. Всего обработано {len(Files_List)} файл(а,ов).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r68g_UYCiN35"
      },
      "source": [
        "# Подведение итогов\n",
        "В процессе работы были получены два варианта датасета. Изначально был создан дата сет, с различными отрицательными нормированными значениями координат ключевых точек (при распознавании YOLO-pose эти координаты были равны 0, но при нормировании они принимали отрицательное значение, причем разное для каждого кадра). Нейросеть, обученная на таком дата сете выдавала неудовлетворительный результат, и точность поднять с помощью перебора архитектуры не удавалось. Поэтому было принято решение изменить функцию extract_predictions так, чтобы всем нормируемым значениям координат ключевых точек, которые не были распознаны YOLO-pose присваивать значения \"-1\". Видеозаписи были заново распознаны и был получен дата сет второй версии. На нем удалось поднять точность до 82%. Визуальная проверка на видеозаписях, которые не \"видела\" нейросеть была уже намного лучше, но так же точность не уадавалось поднять выше. Для увеличения точности было принято решение взять углы рук и ног человека относительно вертикали (8 углов для каждогго человека - плечо, предплечье, бедро и голень). Был увеличен датасет и был заново распознан. С помощью нового генератора был создан датасет с углами и произведен поиск архитектуры с помощью autokeras. Было сделано более 600 trials, была подобрана очень простая нейросеть из слоев dense. ДЛя эксперимента было проведено еще около 400 trials  в autokeras с блоками ConvBlock, RNNBlock и ResNetBlock, изменив при этом размерность датасета, чтобы данные можно было рассматривать как последовательность временных рядов. Но точность осталась на том же уровне, но с более сложной архитектурой. На данный момент выбрана самая простая и быстрая нейросет, которая обладает точностью 90.5% на валидационной выборке. На видеозаписях, которые нейросеть не видела получились хорошие результаты."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
